models:
  'qwen-2.5-coder-1.5B-Instruct-Q4_K_M':
    proxy: 'http://127.0.0.1:8012'
    name: 'Qwen 2.5 1.5B'
    cmd: |
      /opt/homebrew/bin/llama-server
      --host 127.0.0.1
      --port 8012
      -hf unsloth/Qwen2.5-Coder-1.5B-Instruct-128K-GGUF:Q4_K_M
      --ubatch-size 512 
      --batch-size 1024
      --ctx-size 0
      --cache-reuse 256
      --temp 0.7 
      --min-p 0.0 
      --top-p 0.8 
      --top-k 20 
      --repeat-penalty 1.05
      --jinja
  'qwen-2.5-coder-1.5B-Instruct-Q6':
    proxy: 'http://127.0.0.1:8012'
    name: 'Qwen 2.5 1.5B'
    cmd: |
      /opt/homebrew/bin/llama-server
      --host 127.0.0.1
      --port 8012
      -hf unsloth/Qwen2.5-Coder-1.5B-Instruct-GGUF:Q6_K
      --ubatch-size 512 
      --batch-size 1024
      --ctx-size 32768
      --cache-reuse 256
      --temp 0.7 
      --min-p 0.0 
      --top-p 0.8 
      --top-k 20 
      --repeat-penalty 1.05
      --jinja
  'qwen-2.5-coder-3B-Instruct':
    proxy: 'http://127.0.0.1:8012'
    name: 'Qwen 2.5 3B'
    cmd: |
      /opt/homebrew/bin/llama-server
      --host 127.0.0.1
      --port 8012
      -hf unsloth/Qwen2.5-Coder-3B-Instruct-128K-GGUF:Q4_K_M
      --ubatch-size 512 
      --batch-size 1024
      --ctx-size 32768
      --cache-reuse 256
      --temp 0.7 
      --min-p 0.0 
      --top-p 0.8 
      --top-k 20
      --repeat-penalty 1.05
      --jinja
  'qwen-3-4B-thinking-2507':
    proxy: 'http://127.0.0.1:8012'
    name: 'Qwen 3 4B (Thinking 2507)'
    cmd: |
      /opt/homebrew/bin/llama-server
      --host 127.0.0.1
      --port 8012
      -hf bartowski/Qwen_Qwen3-4B-Thinking-2507-GGUF:Q4_K_M
      --ctx-size 16384
      --context-shift
      --temp 0.6 
      --min-p 0.0 
      --top-p 0.95 
      --top-k 20 
      --presence-penalty 1.0
      --jinja
  'qwen-3-4B-instruct-2507':
    proxy: 'http://127.0.0.1:8012'
    name: 'Qwen 3 4B (Instruct 2507)'
    cmd: |
      /opt/homebrew/bin/llama-server
      --host 127.0.0.1
      --port 8012
      -hf bartowski/Qwen_Qwen3-4B-Instruct-2507-GGUF:Q4_K_M
      --ctx-size 16384
      --context-shift
      --temp 0.6 
      --min-p 0.0 
      --top-p 0.95 
      --top-k 20 
      --presence-penalty 1.0
      --jinja
  'granite-4.0-h-micro-3b':
    proxy: 'http://127.0.0.1:8012'
    name: 'Granite 4 Micro 3B'
    cmd: |
      /opt/homebrew/bin/llama-server
      --host 127.0.0.1
      --port 8012
      -hf unsloth/granite-4.0-h-micro-GGUF:Q4_K_M
      --ctx-size 16384
      --context-shift
      --temp 0.0 
      --top-p 1.0 
      --top-k 0 
      --jinja
  'granite-4.0-h-tiny-7b':
    proxy: 'http://127.0.0.1:8012'
    name: 'Granite 4 Tiny 7B'
    cmd: |
      /opt/homebrew/bin/llama-server
      --host 127.0.0.1
      --port 8012
      -hf unsloth/granite-4.0-h-tiny-GGUF:Q4_K_M
      --ctx-size 16384
      --context-shift
      --temp 0.0 
      --top-p 1.0 
      --top-k 0 
      --jinja
  'gemma-3-4b':
    proxy: 'http://127.0.0.1:8012'
    name: 'Gemma 3 4B'
    cmd: |
      /opt/homebrew/bin/llama-server
      --host 127.0.0.1
      --port 8012
      -hf unsloth/gemma-3-4b-it-GGUF:Q4_K_M
      --ctx-size 16384
      --context-shift
      --temp 1.0 
      --top-p 0.95 
      --top-k 64 
      --min-p 0.0
      --repeat-penalty 1.0
      --jinja
  'whisper':
    proxy: 'http://127.0.0.1:9090'
    checkEndpoint: /v1/audio/transcriptions/
    cmd: |
      whisper-server
      --host 127.0.0.1
      --port 9090
      --request-path /v1/audio/transcriptions --inference-path ""
